{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "# **Author: Nico Grisouard, nicolas.grisouard@physics.utoronto.ca**\n",
    "\n",
    "*Supporting textbook chapters for week 10: Chapters 10.1 and 10.2*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Week 10, topics:\n",
    "* Random number generation\n",
    "* Monte Carlo integration\n",
    "\n",
    "Another useful resource: the Scientific Computing Course material offered by SciNet.\n",
    "\n",
    "https://wiki.scinet.utoronto.ca/wiki/index.php/Scientific_Computing_Course#Part_2:_Numerical_Tools_for_Physical_Scientists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Random numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "## General requirements\n",
    "\n",
    "Why we need random numbers:\n",
    "\n",
    "* For randomly sampling a domain (today)\n",
    "* Monte Carlo integration (today)\n",
    "* Monte Carlo simulations (next week)\n",
    "* Stochastic algorithms (we'll see some next week)\n",
    "* Cryptography\n",
    "\n",
    "Q: How can a computer generate random numbers? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "What is a useful random sequence of numbers?\n",
    "* Follows some desired distribution\n",
    "* Unpredictable on a number-by-number basis\n",
    "* Fast to generate (we may need billions of them)\n",
    "* Long period (we may need billions of them)\n",
    "* Uncorrelated\n",
    "\n",
    "Problems with actually random numbers:\n",
    "* generally slow, expensive to generate (remember Buffon needle, Lab 01),\n",
    "* hard/impossible to reproduce for debugging\n",
    "* Often hard to characterize underlying distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Q: How can a computer generate random numbers?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "![](xkcd211.png)\n",
    "\n",
    "http://xkcd.com/211"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Q: How can a computer generate random numbers? \n",
    "A: It can't! \n",
    "\n",
    "The computer can't do anything randomly.\n",
    "\n",
    "2 options:\n",
    "* find physical process that actually is random, have computer store info from that to provide a random number\n",
    "* Use an algorithm for generating a sequence of numbers that approximates the properties of random numbers. This is called a \"Pseudorandom Number Generator\" (PRNG) or a \"Deterministic Random Bit Generator\" (DRBG)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Common Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "![](uR4WuQ0.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Correlations\n",
    "\n",
    "Simple pairwise correlations:\n",
    "$$\\epsilon(N, n) = \\frac1N \\sum_{i=1}^{N}x_i x_{i+n} - \\mathrm E[x^2]$$\n",
    "* $N =$ number of data points\n",
    "* $n = $ correlation \"distance\"\n",
    "* $\\mathrm E[x] = \\sum_{i=1}^N x_i/N$, the expected value.\n",
    "\n",
    "We want to avoid correlations between pairs of numbers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Left: bad PRNG; right: Mersenne Twister\n",
    "\n",
    "![From Katzgrabber, \"Random Numbers in Scientific Computing: an Introduction\" (arXiv: 1005.4117)](Mersenne.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Moments\n",
    "\n",
    "$k^\\text{th}$ moment of sequence of $N$ elements, $\\mu(N, k)$:\n",
    "$$\\mu(N, k) = \\mathrm E[x^k]$$\n",
    "\n",
    "We want to ensure moments of random number distributions also have desired properties."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Other tests\n",
    "\n",
    "* Overlapping permutations: Analyze orders of five consecutive random numbers. The $5!$ possible permutations should occur with equal probability.\n",
    "* ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Linear Congruential Generator\n",
    "\n",
    "* The sequence of numbers produced by a PRNG seem random, but they are reproducible if you start with the same \"seed\" value.\n",
    "* For example (actually a bad choice for a PRNG, but good for illustration): \"Linear Congruential Random Number Generator\":\n",
    "$$x_{i+1} = (ax_i + c)\\mod m$$\n",
    "    E.g. in Python:\n",
    "    `x[i+1] = (a*x[i] + c) % m`\n",
    "* $x_0$ would be the seed,\n",
    "* $m$: large integer, determines period,\n",
    "* For good results: $c$ relatively prime to $m$, $a-1$ is a multiple of $p$ for every prime divisor $p$ of $m$\n",
    "* (e.g., $a-1$ is multiple of $4$ if $m$ is multiple of $4$).\n",
    "* How does computer pick seed $x_0$?  Taking system time is common (dangerous in parallel!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Newman's lcg.py\n",
    "from pylab import plot, show\n",
    "\n",
    "N = 100\n",
    "a = 1664525\n",
    "c = 1013904223\n",
    "m = 4294967296\n",
    "x = 1\n",
    "results = []\n",
    "\n",
    "for i in range(N):\n",
    "    x = (a*x+c) % m\n",
    "    results.append(x)\n",
    "plot(results, \"o\")\n",
    "show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Benefits: \n",
    "* much faster than real random number generators\n",
    "* good for testing code since you can supply the same 'seed' for reproducible outcome using the `seed()` function:\n",
    "\n",
    "    `seed(4219)`\n",
    "\n",
    "    `x = random()`\n",
    "\n",
    "    will always produce the same `x`.\n",
    "\n",
    "* easy to generate many different sequences, just pick many different seeds.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* We want to avoid correlations between pairs of numbers\n",
    "* Can do lots of test that PRNGs producing right \"statistics\" of random numbers!\n",
    "* Python uses a Mersenne twister"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Functions in `random.py` most likely to use:\n",
    "* `random()`: gives a random float uniformly distributed in a the range $[0, 1)$ (all values have equal probability of being selected),\n",
    "* `randrange(m, n)`: Gives a random integer from `m` to `n-1`, inclusive.\n",
    "\n",
    "* If you need a uniformly distributed random float outside the range $[0,1)$, say in range $[a,b)$, then just multiply your answer by $(b-a)$ and shift the argument. For example:\n",
    "\n",
    "    `num = random()`\n",
    "\n",
    "    `shiftnum = (b-a)*(num+a)`\n",
    "    \n",
    "More resources:\n",
    "\n",
    "https://docs.scipy.org/doc/numpy-1.15.1/reference/routines.random.html\n",
    "\n",
    "https://docs.python.org/3/library/random.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "from random import randrange\n",
    "\n",
    "x, y = 0, 0\n",
    "\n",
    "def nextmove(x, y):\n",
    "    dir = randrange(1, 5)\n",
    "    if dir == 1:\n",
    "        x += 1\n",
    "    elif dir == 2:\n",
    "        y += 1\n",
    "    elif dir == 3:\n",
    "        x -= 1\n",
    "    elif dir == 4:\n",
    "        y -= 1\n",
    "    return x, y\n",
    "\n",
    "for i in range(10):\n",
    "    x, y = nextmove(x, y)\n",
    "    print(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# re-do here in class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Non-Uniform distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "What if you need a random number from a non-uniform distribution?\n",
    "\n",
    "* Get a uniformly distributed random number, then use a transformation to make it seem like it comes from a non-uniform distribution.\n",
    "\n",
    "* Consider source of random floats $z$ from a distribution with probability density $q(z)$, i.e., the probability of generating a number in the interval $z$ to $z+\\text dz$ is:\n",
    "$$q(z)\\text dz$$\n",
    "* For a uniform distribution, $q(z)=1$ since for all d$z$, equal probability of number being chosen.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* Now consider transformation of $z$ into new variable, say $x$ using:\n",
    "    $$x=x(z)$$\n",
    "* Then $x$ is also a random number, but will have some other probability distribution, call it $p(x)$.\n",
    "* The probability of generating a value of $x$ between $x$ and $x+\\text dx$ is by definition equal to the probability of generating a value of $z$ between the corresponding $z$ and $z + \\text dz$:\n",
    "    $$p(x) \\text dx = q(z) \\text dz, \\quad \\text{where}\\ x=x(z)$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* Goal: find a function $x(z)$ so that $x$ has the distribution we want.\n",
    "* Then we can use `random()` to get a uniformly distributed random number $z$ and transform it to $x$ using:\n",
    "$$q(z) = 1 \\quad \\text{over}\\quad [0,1)$$\n",
    "$$q(z)\\text dz = p(x)\\text d x$$\n",
    "$$\\Rightarrow \\int_0^z 1 \\text d z' = z = \\int_0^{x(z)} p(x')\\text d x'.$$\n",
    "* Plug in your $p(x)$ for the probability distribution you need and integrate to find $z(x)$ (if you can!)\n",
    "* Even then: might not be possible to solve for $x(z)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Example: exponential distribution\n",
    "$$q(z) = 1 \\quad \\text{over}\\quad [0,1)$$\n",
    "$$p(x) = a\\exp(-a x)  \\quad \\text{over}\\quad [0,\\infty)$$\n",
    "$$\\Rightarrow\\ z = \\int_0^{x(z)}a\\exp(-ax')\\text d x' = 1 - \\exp(-ax)$$\n",
    "$$\\Rightarrow\\ x = -\\frac{\\ln(1-z)}a.$$\n",
    "* Draw a number $z$ in $[0,1)$,\n",
    "* $x(z)$ has the desired distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* Simulate random physical processes like diffusion, radioactive decay, Brownian motion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![](Lab10-Q1a.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Monte Carlo integration\n",
    "\n",
    "![Par I, Katonams, CC BY-SA 3.0, https://commons.wikimedia.org/w/index.php?curid=2480853](Whole_monaco.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## What it is \n",
    "\n",
    "Solving Integrals:  \"Monte Carlo Integration\"\n",
    "* Sounds great in theory. Would never work in practice without computers.\n",
    "* 3 Monte Carlo techniques you will use in the lab:\n",
    "    * \"hit or miss\" or \"standard\" Monte Carlo\n",
    "    * \"mean value\" Monte Carlo\n",
    "    * \"importance sampling\" Monte Carlo\t\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "You've already learned a bunch of different methods for integrating, why introduce another one?  (Especially since its convergence/error properties are worse than the other methods):\n",
    "\n",
    "Reason 1: Good for pathological functions or just fast-varying functions. \n",
    "\n",
    "![Newman's 10.4](fig10-4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Reason 2: MUCH faster for multi-dimensional integrals.\n",
    "\n",
    "The \"curse of dimensionality\":\n",
    "* For a dimension $d$ integral, you need $O(n^d)$ grid points.\n",
    "* E.g. with trapezoid, Simpson or Gaussian integration: for $n=1000$ points, a $10$-$d$ integral need $10^{30}$ grid points! Yikes!\n",
    "\n",
    "* Or: if you can afford $N$ points, your grid has side length $O(N^{1/d})$.\n",
    "* For trapezoid integration, error $\\epsilon = O(h^2) \\propto 1/N^{2/d}$.\n",
    "* E.g., for a 10-$d$ integral, $\\epsilon \\propto 1/N^{1/5}$.\n",
    "\n",
    "* Monte Carlo: $\\epsilon \\propto 1/N^{1/2}$, regardless of $d$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Reason 3: much easier to implement in complicated domains (i.e., complicated boundaries of integration)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "![](The_Blob_(1958)_theatrical_poster.jpg)\n",
    "\n",
    "Try finding the volume of the Blob with Gaussian quadrature!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Implementation\n",
    "\n",
    "Use random numbers to pick points at which to evaluate integrand.\n",
    "\n",
    "![](MC_Implementation.png)\n",
    "\n",
    "* Simple and flexible.\n",
    "* Can generalize to focus on important parts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Hit-or-miss MC\n",
    "\n",
    "* If your function \"fits\" in a finite region where we want to integrate from $x=0$ to $x=2$:\n",
    "$$f(x) = \\sin^2\\left[\\frac{1}{x(2-x)}\\right]$$\n",
    "![Newman's 10.4](fig10-4.png)\n",
    "* function fits in box of height 1, width 2. \n",
    "* Define area of box: $A$ (this is important! It is the piece of info we will leverage).\n",
    "* Integral of function is shaded area in the box  (call it $I$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* Probability that your random point falls in the shaded region is $p = I/A$.\n",
    "* Algorithm:\n",
    "    1. Randomly pick $N$ locations in the box (lots of them).\n",
    "    2. Count the number of locations that are in the shaded region (call the count $k$).\n",
    "    3. The fraction of points in the shaded region is $k/N$. This approximates the probability $p$.\n",
    "Solve for $I$:\n",
    "$$P = \\frac{I}{A} \\approx \\frac{k}N\\ \\Rightarrow\\ I\\approx \\frac{kA}{N}.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Can estimate the error on the integral (text gives derivation on page 467 from probability theory):\n",
    "\n",
    "* The 'Expected Error' (standard deviation):\n",
    "$$\\sigma = \\sqrt{\\frac{I(A-I)}{N}}.$$\n",
    "* Notice it varies as $N^{-1/2}$. This is very **slow**!\n",
    "* Compare:\n",
    "    * Trapezoid Rule: error varies as $N^{-2}$,\n",
    "\t* Simpson's Rule: error varies as $N^{-4}$.\n",
    "* (but careful to compare apples with apples, see earlier!)\n",
    "* This is why you only use Monte Carlo integration if you absolutely have to."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Example: exercise 10.5(a) from the text.\n",
    "\n",
    "Write a program to evaluate\n",
    "$$I = \\int_0^2 \\sin\\left[\\frac1{x(2-x)}\\text d x\\right]$$\n",
    "using the \"hit-or-miss\" method.\n",
    "* Use $N= 10000$ points.\n",
    "* Also evaluate the error on your method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np  # I'll use the numpy \n",
    "\n",
    "def f(x): return np.sin(1/((x-a)*(b-x)))**2  # the function to integrate\n",
    "\n",
    "N = 10000\n",
    "k = 0\n",
    "a = 0.\n",
    "b = 2.\n",
    "\n",
    "for i in range(N):\n",
    "    x_sampl = (b-a)*np.random.random()\n",
    "    y_sampl = np.random.random()\n",
    "    if y_sampl <= f(x_sampl):\n",
    "        k += 1\n",
    "\n",
    "A = (b-a)*1.\n",
    "I = A*k/N\n",
    "print(I)\n",
    "\n",
    "# error\n",
    "sigma_HM = np.sqrt(I*(A-I)/N)  # HM stands for hit-or-miss\n",
    "print('error = ', sigma_HM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Re-do here in class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Mean value MC\n",
    "\n",
    "* Use the definition of an average (or mean value):\n",
    "$$I = \\int_a^b f(x)\\text d x,$$\n",
    "$$\\left<f\\right> = \\frac1{b-a}\\int_a^b f(x) \\text d x = \\frac{I}{b-a}$$\n",
    "$$\\Rightarrow\\ I = (b-a)\\left<f\\right>$$\n",
    "\n",
    "* Use random numbers to estimate $\\left<f\\right>$. Evaluate $f$ at $N$ random $x$'s, then calculate:\n",
    "$$\\left<f\\right>\\approx\\frac1N\\sum_{i=1}^N f(x_i) \\ \\Rightarrow \\ I\\approx \\frac{b-a}{N}\\sum_{i=1}^N f(x_i).$$\n",
    "* (\"hit-or-miss\": we chose $N$ random point over $(x, y)$.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Error estimate.\n",
    "* Can estimate the error on the integral (text gives derivation on pages 468-469 from probability theory):\n",
    "    \"Expected Error\":\n",
    "$$\\sigma = (b-a)\\sqrt{\\frac{\\text{var} f}N}$$\n",
    "$$\\text{var} f = \\left<f^2\\right> - \\left< f \\right>^2.$$\n",
    "* Notice it also varies as $N^{-1/2}$.\n",
    "    However, it turns out the leading constant is smaller than with the hit or miss method.\n",
    "    *Note: I have not been able to figure out if this result is always true, or usually true. Newman's wording seems to indicate that it is always true, but I can't quite figure out why.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Example: exercise 10.5(b) from the text.\n",
    "\n",
    "Write a program to evaluate\n",
    "$$I = \\int_0^2 \\sin\\left[\\frac1{x(2-x)}\\text d x\\right]$$\n",
    "using the mean value method.\n",
    "* Use $N = 10000$ points.\n",
    "* Also evaluate the error on your method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def f(x): return np.sin(1/((x-a)*(b-x)))**2\n",
    "\n",
    "N = 10000\n",
    "a = 0.\n",
    "b = 2.\n",
    "k = 0  # will contain the average\n",
    "k2 = 0  # will be used for variance\n",
    "\n",
    "for i in range(N):\n",
    "    x = (b-a)*np.random.random()\n",
    "    k += f(x)\n",
    "    k2 += f(x)**2\n",
    "\n",
    "I = k * (b-a) / N\n",
    "print(I)\n",
    "\n",
    "# error\n",
    "var = k2/N - (k/N)**2  # variance <f**2> - <f>**2\n",
    "sigma_MV = (b-a)*np.sqrt(var/N)  # MV stands for Mean Value\n",
    "print('error = ', sigma_MV)\n",
    "print('recall error in hit-or-miss = ', sigma_HM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Re-do in class here:\n",
    "def f(x): return np.sin(1/((x-a)*(b-x)))**2\n",
    "\n",
    "N = 10000\n",
    "a = 0.\n",
    "b = 2.\n",
    "k = 0  # will contain the average\n",
    "\n",
    "for i in range(N):\n",
    "    x = (b-a)*np.random.random()\n",
    "    k += \n",
    "\n",
    "I = k * \n",
    "print(I)\n",
    "\n",
    "# error\n",
    "var =   # variance <f**2> - <f>**2\n",
    "sigma_MV =   # MV stands for Mean Value\n",
    "print('error = ', sigma_MV)\n",
    "print('recall error in hit-or-miss = ', sigma_HM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Importance sampling MC\n",
    "\n",
    "* Good to use when your integrand contains a divergence: want to place more points in region where the integrand is large to better estimate the integral, also when you want to integrate out to infinity\n",
    "* Illustrative example (obviously a bad one for Monte-Carlo, but good for making my point):\n",
    "$$f(x) = 1\\quad \\text{for}\\quad c<x<d, \\qquad f(x) = 0\\quad \\text{otherwise}.$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "x = np.linspace(0, 1, 1000)\n",
    "f = 0.*x\n",
    "for i, xs in enumerate(x):\n",
    "    if 0.33 < xs < 0.35:\n",
    "        f[i] = 1.\n",
    "plt.plot(x, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* Easy to miss the region between $c$ and $d$ with uniformly sampled points\n",
    "* evaluating the integral many times using Mean Value or Hit/Miss MC (with different randomly sampled points) can give very different answers, much larger than the expected error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* Solution: sample \"important\" regions more frequently.\n",
    "    I.e., come up with a non-uniformly distributed set of random numbers.\n",
    "    This is called \"Importance Sampling\".\n",
    "\n",
    "* Text shows that using a weight function $w(x)$, you can always write:\n",
    "$$I = \\int_a^b f(x)\\text d x = \\underbrace{\\left<\\frac{f(x)}{w(x)}\\right>_w}_{weighted\\\\ average}\\int_a^b w(x)\\text d x.$$\n",
    "\n",
    "* Goal: find a weight function that gets rid of pathologies in integrand $f(x)$.\n",
    "    E.g., if $f(x)$ has a divergence, factor the divergence out and hence get a sum (in the $\\left<\\right>$) that is well behaved (i.e. doesn't vary much each time you do the integral)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Example (you will use in Lab 9):\n",
    "$$I = \\int_0^1 \\frac{x^{-1/2}}{1 + \\exp(x)}\\text d x,$$\n",
    "diverges as $x\\to 0$ because of numerator.\n",
    "\n",
    "Fine, let $w(x)= numerator$.\n",
    "Then\n",
    "$$\\left<\\frac{f(x)}{w(x)}\\right> = \\frac1N \\sum_{i=1}^{N}\\frac{f(x_i)}{w(x_i)} = \\frac1N \\sum_{i=1}^{N}\\frac{1}{1 + \\exp(x_i)},$$\n",
    "which is much better behaved than \n",
    "$$\\left<f(x)\\right> = \\frac1N \\sum_{i=1}^{N}\\frac{x^{-1/2}}{1 + \\exp(x_i)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* When you've chosen your weight function, you then need to make sure to randomly sample points from the non-uniform distribution:\n",
    "    $$p(x) = \\frac{w(x)}{\\int_a^b w(x)\\text d x}$$\n",
    "    Use the transformation method described earlier in this lecture to take a uniformly distribution random $z$ and find the corresponding $x$ for this distribution. \n",
    "    \n",
    "* \"Expected error\":\n",
    "    $$\\sigma = \\sqrt{\\frac{\\text{var}(f/w)}{N}}\\int_a^b w(x)\\text d x.$$\n",
    "    Yes, it also varies as $N^{-1/2}$.   If you do the integral many times, your values should mostly fall within the expected error.\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python [conda env:anaconda]",
   "language": "python",
   "name": "conda-env-anaconda-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
